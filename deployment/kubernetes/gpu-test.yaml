apiVersion: v1
kind: Pod
metadata:
  name: gpu-check-pytorch
spec:
  restartPolicy: Never
  nodeSelector:
    node.kubernetes.io/instance-type: g2-gpu-rtx4000a1-m
  containers:
    - name: gpu-check-container
      image: pytorch/pytorch:latest
      command: ["python3", "-c"]
      args:
        - |
          import torch
          print(f"PyTorch version: {torch.__version__}")
          print(f"CUDA available: {torch.cuda.is_available()}")
          if torch.cuda.is_available():
              print(f"GPU count: {torch.cuda.device_count()}")
              print(f"GPU name: {torch.cuda.get_device_name(0)}")
      resources:
        limits:
          nvidia.com/gpu: 1
          memory: "8Gi"
          cpu: "2"
